2025-12-30 19:44:55 [scrapy.utils.log] INFO: Scrapy 2.13.4 started (bot: stock_company_scraper)
2025-12-30 19:44:55 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.11.9',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'Windows-10-10.0.19045-SP0'}
2025-12-30 19:44:55 [scrapy.addons] INFO: Enabled addons:
[]
2025-12-30 19:44:55 [scrapy.extensions.telnet] INFO: Telnet Password: 32e392f507c4acf0
2025-12-30 19:44:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-12-30 19:44:55 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'stock_company_scraper',
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'crawling_log.txt',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'stock_company_scraper.spiders',
 'SPIDER_MODULES': ['stock_company_scraper.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}
2025-12-30 19:44:55 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-12-30 19:44:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-12-30 19:44:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-12-30 19:44:56 [scrapy.middleware] INFO: Enabled item pipelines:
['stock_company_scraper.pipelines.StockCompanyScraperPipeline',
 'stock_company_scraper.pipelines.SQLiteStoragePipeline']
2025-12-30 19:44:56 [scrapy.core.engine] INFO: Spider opened
2025-12-30 19:44:56 [py.warnings] WARNING: C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\site-packages\scrapy\core\spidermw.py:433: ScrapyDeprecationWarning: stock_company_scraper.spiders.ads_spider.EventSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-12-30 19:44:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-12-30 19:44:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-12-30 19:44:56 [scrapy-playwright] INFO: Starting download handler
2025-12-30 19:44:56 [scrapy-playwright] INFO: Starting download handler
2025-12-30 19:44:57 [event_ads] INFO: ===> GẶP TIN CŨ API: [Thông báo thay đổi nhân sự - bổ nhiệm người phụ trách quản trị công ty kể từ 01/01/2026]. DỪNG QUÉT GIA TĂNG.
2025-12-30 19:44:57 [scrapy.core.engine] INFO: Closing spider (finished)
2025-12-30 19:44:57 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: news.json
2025-12-30 19:44:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 448,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6764,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.303464,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 12, 30, 12, 44, 57, 335738, tzinfo=datetime.timezone.utc),
 'items_per_minute': 0.0,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'responses_per_minute': 60.0,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 12, 30, 12, 44, 56, 32274, tzinfo=datetime.timezone.utc)}
2025-12-30 19:44:57 [scrapy.core.engine] INFO: Spider closed (finished)
2025-12-30 19:44:57 [scrapy-playwright] INFO: Closing download handler
2025-12-30 19:44:57 [scrapy-playwright] INFO: Closing download handler
2025-12-30 19:44:57 [asyncio] ERROR: Task was destroyed but it is pending!
task: <Task pending name='Task-1' coro=<_ThreadedLoopAdapter._process_queue() running at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\site-packages\scrapy_playwright\_utils.py:132> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_chain_future.<locals>._call_set_state() at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\futures.py:400]>
2025-12-30 19:44:57 [asyncio] ERROR: Task was destroyed but it is pending!
task: <Task pending name='Task-30' coro=<Queue.join() running at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\queues.py:242> cb=[_chain_future.<locals>._call_set_state() at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\futures.py:400]>
2025-12-30 19:50:57 [scrapy.utils.log] INFO: Scrapy 2.13.4 started (bot: stock_company_scraper)
2025-12-30 19:50:57 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.11.9',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'Windows-10-10.0.19045-SP0'}
2025-12-30 19:50:57 [scrapy.addons] INFO: Enabled addons:
[]
2025-12-30 19:50:57 [scrapy.extensions.telnet] INFO: Telnet Password: b2c557c786528af4
2025-12-30 19:50:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-12-30 19:50:57 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'stock_company_scraper',
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'crawling_log.txt',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'stock_company_scraper.spiders',
 'SPIDER_MODULES': ['stock_company_scraper.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}
2025-12-30 19:50:57 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-12-30 19:50:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-12-30 19:50:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-12-30 19:50:57 [scrapy.middleware] INFO: Enabled item pipelines:
['stock_company_scraper.pipelines.StockCompanyScraperPipeline',
 'stock_company_scraper.pipelines.SQLiteStoragePipeline']
2025-12-30 19:50:57 [scrapy.core.engine] INFO: Spider opened
2025-12-30 19:50:57 [py.warnings] WARNING: C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\site-packages\scrapy\core\spidermw.py:433: ScrapyDeprecationWarning: stock_company_scraper.spiders.ads_spider.EventSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-12-30 19:50:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-12-30 19:50:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-12-30 19:50:57 [scrapy-playwright] INFO: Starting download handler
2025-12-30 19:50:57 [scrapy-playwright] INFO: Starting download handler
2025-12-30 19:50:58 [event_ads] INFO: ===> GẶP TIN CŨ API: [Thông báo thay đổi nhân sự - bổ nhiệm người phụ trách quản trị công ty kể từ 01/01/2026]. DỪNG QUÉT GIA TĂNG.
2025-12-30 19:50:59 [scrapy.core.engine] INFO: Closing spider (finished)
2025-12-30 19:50:59 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: news.json
2025-12-30 19:50:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 448,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6764,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.201876,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 12, 30, 12, 50, 59, 3772, tzinfo=datetime.timezone.utc),
 'items_per_minute': 0.0,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'responses_per_minute': 60.0,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 12, 30, 12, 50, 57, 801896, tzinfo=datetime.timezone.utc)}
2025-12-30 19:50:59 [scrapy.core.engine] INFO: Spider closed (finished)
2025-12-30 19:50:59 [scrapy-playwright] INFO: Closing download handler
2025-12-30 19:50:59 [scrapy-playwright] INFO: Closing download handler
2025-12-30 19:50:59 [asyncio] ERROR: Task was destroyed but it is pending!
task: <Task pending name='Task-1' coro=<_ThreadedLoopAdapter._process_queue() running at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\site-packages\scrapy_playwright\_utils.py:132> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_chain_future.<locals>._call_set_state() at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\futures.py:400]>
2025-12-30 19:50:59 [asyncio] ERROR: Task was destroyed but it is pending!
task: <Task pending name='Task-30' coro=<Queue.join() running at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\queues.py:242> cb=[_chain_future.<locals>._call_set_state() at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\futures.py:400]>
2025-12-30 19:53:20 [scrapy.utils.log] INFO: Scrapy 2.13.4 started (bot: stock_company_scraper)
2025-12-30 19:53:20 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.11.9',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'Windows-10-10.0.19045-SP0'}
2025-12-30 19:53:20 [scrapy.addons] INFO: Enabled addons:
[]
2025-12-30 19:53:20 [scrapy.extensions.telnet] INFO: Telnet Password: 2551792ff1bb67ab
2025-12-30 19:53:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-12-30 19:53:20 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'stock_company_scraper',
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'crawling_log.txt',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'stock_company_scraper.spiders',
 'SPIDER_MODULES': ['stock_company_scraper.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}
2025-12-30 19:53:20 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-12-30 19:53:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-12-30 19:53:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-12-30 19:53:20 [scrapy.middleware] INFO: Enabled item pipelines:
['stock_company_scraper.pipelines.StockCompanyScraperPipeline',
 'stock_company_scraper.pipelines.SQLiteStoragePipeline']
2025-12-30 19:53:20 [scrapy.core.engine] INFO: Spider opened
2025-12-30 19:53:20 [py.warnings] WARNING: C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\site-packages\scrapy\core\spidermw.py:433: ScrapyDeprecationWarning: stock_company_scraper.spiders.ads_spider.EventSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-12-30 19:53:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-12-30 19:53:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-12-30 19:53:20 [scrapy-playwright] INFO: Starting download handler
2025-12-30 19:53:20 [scrapy-playwright] INFO: Starting download handler
2025-12-30 19:53:21 [event_ads] INFO: ===> GẶP TIN CŨ API: [Thông báo thay đổi nhân sự - bổ nhiệm người phụ trách quản trị công ty kể từ 01/01/2026]. DỪNG QUÉT GIA TĂNG.
2025-12-30 19:53:21 [scrapy.core.engine] INFO: Closing spider (finished)
2025-12-30 19:53:21 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: news.json
2025-12-30 19:53:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 448,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6764,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.176103,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 12, 30, 12, 53, 21, 733984, tzinfo=datetime.timezone.utc),
 'items_per_minute': 0.0,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'responses_per_minute': 60.0,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 12, 30, 12, 53, 20, 557881, tzinfo=datetime.timezone.utc)}
2025-12-30 19:53:21 [scrapy.core.engine] INFO: Spider closed (finished)
2025-12-30 19:53:21 [scrapy-playwright] INFO: Closing download handler
2025-12-30 19:53:21 [scrapy-playwright] INFO: Closing download handler
2025-12-30 19:53:21 [asyncio] ERROR: Task was destroyed but it is pending!
task: <Task pending name='Task-1' coro=<_ThreadedLoopAdapter._process_queue() running at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\site-packages\scrapy_playwright\_utils.py:132> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_chain_future.<locals>._call_set_state() at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\futures.py:400]>
2025-12-30 19:53:21 [asyncio] ERROR: Task was destroyed but it is pending!
task: <Task pending name='Task-30' coro=<Queue.join() running at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\queues.py:242> cb=[_chain_future.<locals>._call_set_state() at C:\Users\vuong\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\futures.py:400]>
