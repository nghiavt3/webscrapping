import sqlite3
import tkinter as tk
import sys
import hashlib
import time
from tkinter import ttk, messagebox
from datetime import datetime, date, timedelta
import os
import threading
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
import winsound  # Th√™m th∆∞ vi·ªán ph√°t √¢m thanh tr√™n Windows

# --- 1. KI·ªÇM TRA QUY·ªÄN TRUY C·∫¨P (DYNAMIC TOKEN) ---
def check_access():
    if len(sys.argv) < 2:
        sys.exit("Truy c·∫≠p b·ªã ch·∫∑n! Vui l√≤ng kh·ªüi ƒë·ªông t·ª´ App Web.")

    received_token = sys.argv[1]
    valid_tokens = []
    for offset in [0, -1]:
        t_str = (datetime.now() + timedelta(minutes=offset)).strftime('%Y-%m-%d %H:%M')
        raw = f"MySecretKey_{t_str}"
        valid_tokens.append(hashlib.sha256(raw.encode()).hexdigest())

    if received_token not in valid_tokens:
        root_auth = tk.Tk()
        root_auth.withdraw()
        messagebox.showerror("L·ªói b·∫£o m·∫≠t", "Token h·∫øt h·∫°n ho·∫∑c kh√¥ng h·ª£p l·ªá!")
        root_auth.destroy()
        sys.exit()

check_access()

# --- 2. C·∫§U H√åNH D·ªÆ LI·ªÜU ---
try:
    from spider_names import ALL_SPIDERS
    ALL_SPIDERS = sorted(ALL_SPIDERS) 
except ImportError:
    ALL_SPIDERS = [] 

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATABASE_NAME = os.path.join(BASE_DIR, 'stock_events.db')
current_view_data = [] 
last_count = 0  # Bi·∫øn l∆∞u tr·ªØ s·ªë l∆∞·ª£ng tin ƒë·ªÉ so s√°nh ph√°t √¢m thanh

# --- 3. LOGIC TRUY V·∫§N & X·ª¨ L√ù ---

def fetch_history_data(table_name):
    global current_view_data
    if not table_name: return
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute(f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table_name}")
        rows = cursor.fetchall()
        
        processed_data = []
        for row in rows:
            new_row = list(row)
            if not new_row[2] or new_row[2] == "None":
                new_row[2] = row[4].split(' ')[0] if row[4] else "N/A"
            processed_data.append(tuple(new_row))
            
        # S·∫Øp x·∫øp l·∫°i danh s√°ch ƒë√£ x·ª≠ l√Ω
        current_view_data = sorted(processed_data, key=lambda x: x[2], reverse=True)
        
        update_treeview(tree, current_view_data)
        root.title(f"Stock Scraper - B·∫£ng {table_name} ({len(current_view_data)} b·∫£n ghi)")
    except Exception as e:
        messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ ƒë·ªçc b·∫£ng {table_name}: {e}")
    finally:
        conn.close()

def get_filtered_data(days_offset=None):
    today_dt = date.today()
    # T√≠nh m·ªëc th·ªùi gian b·∫Øt ƒë·∫ßu (VD: 7 ng√†y tr∆∞·ªõc)
    limit_date = today_dt - timedelta(days=days_offset-1) if days_offset else today_dt
    
    all_data = []
    if not os.path.exists(DATABASE_NAME): return []
    
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'event_%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        for table in tables:
            # L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu (ho·∫∑c c√≥ th·ªÉ gi·ªõi h·∫°n 1 th√°ng g·∫ßn ƒë√¢y ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng)
            query = f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table}"
            cursor.execute(query)
            rows = cursor.fetchall()
            
            for row in rows:
                # Logic quan tr·ªçng: N·∫øu date (row[2]) l√† None th√¨ d√πng scraped_at (row[4])
                raw_date_str = row[2] if row[2] and row[2] != "None" else row[4]
                
                if raw_date_str:
                    try:
                        # Ch·ªâ l·∫•y ph·∫ßn YYYY-MM-DD t·ª´ chu·ªói ng√†y (ph√≤ng tr∆∞·ªùng h·ª£p scraped_at c√≥ gi·ªù)
                        clean_date_str = raw_date_str.split(' ')[0]
                        record_date = datetime.strptime(clean_date_str, '%Y-%m-%d').date()
                        
                        # Ki·ªÉm tra xem record_date c√≥ n·∫±m trong kho·∫£ng mong mu·ªën kh√¥ng
                        if record_date >= limit_date:
                            # T·∫°o b·∫£n ghi m·ªõi ƒë·ªÉ hi·ªÉn th·ªã, thay th·∫ø gi√° tr·ªã None b·∫±ng ng√†y scraped_at
                            new_row = list(row)
                            new_row[2] = clean_date_str # C·∫≠p nh·∫≠t c·ªôt Date hi·ªÉn th·ªã
                            all_data.append(tuple(new_row))
                    except:
                        continue
    finally: 
        conn.close()
    
    # S·∫Øp x·∫øp theo ng√†y (c·ªôt index 2) gi·∫£m d·∫ßn
    return sorted(all_data, key=lambda x: x[2], reverse=True)

def get_newly_scraped_data():
    today_str = date.today().strftime('%Y-%m-%d')
    all_data = []
    if not os.path.exists(DATABASE_NAME): return []
    
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'event_%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        for table in tables:
            # L·ªçc tr·ª±c ti·∫øp b·∫±ng SQL theo c·ªôt scraped_at
            query = f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table} WHERE scraped_at LIKE ?"
            cursor.execute(query, (f"{today_str}%",))
            rows = cursor.fetchall()
            
            for row in rows:
                new_row = list(row)
                if not new_row[2] or new_row[2] == "None":
                    new_row[2] = row[4].split(' ')[0]
                all_data.append(tuple(new_row))
    finally:
        conn.close()
    
    # S·∫Øp x·∫øp theo th·ªùi gian Scrape m·ªõi nh·∫•t l√™n ƒë·∫ßu (c·ªôt index 4)
    return sorted(all_data, key=lambda x: x[4], reverse=True)

def perform_search():
    query = search_var.get().strip().upper()
    if not query:
        update_treeview(tree, current_view_data)
        return
    filtered = [row for row in current_view_data if query in str(row[1]).upper()]
    update_treeview(tree, filtered)

def run_parallel_logic(progress_bar, run_btn):
    total = len(ALL_SPIDERS)
    if total == 0: return
    try:
        max_parallel = int(worker_combo.get())
    except:
        max_parallel = 3

    completed = 0
    with ThreadPoolExecutor(max_workers=max_parallel) as executor:
        futures = {executor.submit(lambda s: subprocess.run(['scrapy', 'crawl', s], shell=True, cwd=BASE_DIR), s): s for s in ALL_SPIDERS}
        for future in as_completed(futures):
            completed += 1
            root.after(0, lambda p=(completed/total)*100: progress_bar.config(value=p))
            root.after(0, lambda c=completed, t=total: run_btn.config(text=f"‚è≥ ({c}/{t})..."))
            
    root.after(0, lambda: finalize_run(run_btn))

def finalize_run(run_btn):
    run_btn.config(state=tk.NORMAL, text="üöÄ Ch·∫°y Scrapers")
    messagebox.showinfo("Xong", "ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu m·ªõi!")
    update_display("today")

# --- N√ÇNG C·∫§P: H√ÄM T·ª∞ ƒê·ªòNG C·∫¨P NH·∫¨T V√Ä B√ÅO √ÇM THANH ---
def auto_refresh():
    global last_count
    # L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t c·ªßa h√¥m nay ƒë·ªÉ ki·ªÉm tra
    data_today = get_filtered_data(days_offset=1)
    current_count = len(data_today)

    # N·∫øu s·ªë l∆∞·ª£ng tin h√¥m nay tƒÉng l√™n so v·ªõi l·∫ßn cu·ªëi ki·ªÉm tra
    if current_count > last_count and last_count != 0:
        # Ph√°t ti·∫øng Ting (t·∫ßn s·ªë 1000Hz, k√©o d√†i 500ms)
        winsound.Beep(1000, 500)
        # C·∫≠p nh·∫≠t l·∫°i giao di·ªán ƒë·ªÉ hi·ªÉn th·ªã tin m·ªõi
        update_display("today")
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ƒê√£ c·∫≠p nh·∫≠t {current_count - last_count} tin m·ªõi!")
    
    # C·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng m·ªõi nh·∫•t v√†o b·ªô nh·ªõ
    last_count = current_count
    
    # L·∫≠p l·ªãch ch·∫°y l·∫°i sau 5 ph√∫t (300,000 ms)
    root.after(300000, auto_refresh)

# --- 4. GIAO DI·ªÜN GUI ---

def update_treeview(tree_widget, data):
    today_str = date.today().strftime('%Y-%m-%d')
    for item in tree_widget.get_children(): tree_widget.delete(item)
    for row in data:
        # 1. ƒê·ªãnh nghƒ©a row_id t·ª´ c·ªôt ƒë·∫ßu ti√™n (index 0) c·ªßa row
        row_id = str(row[0]) if row[0] else ""
        summary_text = str(row[3]).lower()
        scraped_at = str(row[4])
        tags = []
        if scraped_at.startswith(today_str):
            tags.append('new_scraped')
        if "NODATE" in row_id:
            tags.append('nodate_row')
        else:
            # Ch·ªâ g√°n m√†u theo lo·∫°i tin n·∫øu kh√¥ng ph·∫£i l√† d√≤ng NODATE
            if "gi·∫£i th·ªÉ" in summary_text or "thu h·ªìi v·ªën" in summary_text:
                tags.append('priority_keyword')
            elif "c·ªï t·ª©c" in summary_text: tags.append('co_tuc')
            elif "chuy·ªÉn nh∆∞·ª£ng" in summary_text: tags.append('chuyen_nhuong')
            elif "ni√™m y·∫øt c·ªï phi·∫øu" in summary_text: tags.append('niem_yet')
            elif "ngh·ªã quy·∫øt ƒëhƒëcƒë" in summary_text: tags.append('nghi_quyet')
        
        tags.append(row[6]) 
        tree_widget.insert('', 'end', values=row[:6], tags=tags)

def update_display(mode="today"):
    global current_view_data, last_count
    
    if mode == "newly":
        current_view_data = get_newly_scraped_data()
        title_prefix = "M·ªõi c·∫≠p nh·∫≠t h√¥m nay"
    else:
        days = 1 if mode == "today" else 7
        current_view_data = get_filtered_data(days_offset=days)
        title_prefix = 'H√¥m nay' if days==1 else '7 ng√†y qua'

    # ƒê·ªìng b·ªô s·ªë l∆∞·ª£ng ƒë·ªÉ b√°o √¢m thanh
    if mode == "newly" or mode == "today":
        last_count = len(current_view_data)
        
    update_treeview(tree, current_view_data)
    search_var.set("")
    root.title(f"Stock Scraper - {title_prefix} ({len(current_view_data)})")


def on_item_select(event):
    selected = tree.focus()
    if not selected: return
    tags = tree.item(selected, 'tags')
    if tags:
        detail_box.config(state=tk.NORMAL)
        detail_box.delete('1.0', tk.END)
        detail_box.insert(tk.END, tags[-1])
        detail_box.config(state=tk.DISABLED)

def on_combo_confirm(event=None):
    user_input = combo.get().strip().lower()
    if not user_input: return
    if user_input in ALL_SPIDERS:
        fetch_history_data(user_input)
        return
    target_table = f"event_{user_input}"
    if target_table in ALL_SPIDERS:
        combo.set(target_table)
        fetch_history_data(target_table)
    else:
        matches = [s for s in ALL_SPIDERS if user_input in s]
        if matches:
            combo.set(matches[0])
            fetch_history_data(matches[0])
        else:
            messagebox.showwarning("Kh√¥ng t√¨m th·∫•y", f"Kh√¥ng t√¨m th·∫•y b·∫£ng n√†o kh·ªõp v·ªõi '{user_input}'")

def run_auto_script():
    script_path = os.path.join(BASE_DIR, 'auto_run.py')
    if os.path.exists(script_path):
        try:
            # S·ª≠ d·ª•ng Popen ƒë·ªÉ ch·∫°y script ƒë·ªôc l·∫≠p, kh√¥ng l√†m treo giao di·ªán GUI
            subprocess.Popen([sys.executable, script_path], cwd=BASE_DIR, shell=False)
            messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ k√≠ch ho·∫°t ch·∫ø ƒë·ªô Auto Run (Ch·∫°y ng·∫ßm).")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ kh·ªüi ch·∫°y auto_run.py: {e}")
    else:
        messagebox.showwarning("L·ªói", "Kh√¥ng t√¨m th·∫•y file auto_run.py trong th∆∞ m·ª•c!")
# KH·ªûI T·∫†O C·ª¨A S·ªî
root = tk.Tk()
root.title("Stock Scraper Pro")
root.geometry("1200x850")

main_frame = ttk.Frame(root, padding="15")
main_frame.pack(fill='both', expand=True)

# 1. Khu v·ª±c B·ªô l·ªçc & T√¨m ki·∫øm
top_frame = ttk.LabelFrame(main_frame, text="üîç C√¥ng c·ª• l·ªçc nhanh", padding="10")
top_frame.pack(fill='x', pady=(0, 10))

ttk.Label(top_frame, text="M√£ CP:").pack(side='left', padx=2)
search_var = tk.StringVar()
search_entry = ttk.Entry(top_frame, textvariable=search_var, width=12)
search_entry.pack(side='left', padx=5)
search_entry.bind('<Return>', lambda e: perform_search())
ttk.Button(top_frame, text="T√¨m", command=perform_search).pack(side='left', padx=2)

ttk.Separator(top_frame, orient='vertical').pack(side='left', fill='y', padx=10)
ttk.Button(top_frame, text="üìÖ H√¥m nay", command=lambda: update_display("today")).pack(side='left', padx=2)
ttk.Button(top_frame, text="‚ö° M·ªõi c·∫≠p nh·∫≠t", command=lambda: update_display("newly")).pack(side='left', padx=2)
ttk.Button(top_frame, text="üóìÔ∏è 7 Ng√†y qua", command=lambda: update_display("week")).pack(side='left', padx=2)

ttk.Label(top_frame, text=" | T√¨m m√£ ngu·ªìn:").pack(side='left', padx=5)
combo = ttk.Combobox(top_frame, values=ALL_SPIDERS, state='normal', width=22)
combo.pack(side='left', padx=2)
combo.bind('<<ComboboxSelected>>', on_combo_confirm)
combo.bind('<Return>', on_combo_confirm)

# 2. B·∫£ng hi·ªÉn th·ªã Treeview
tree = ttk.Treeview(main_frame, columns=('ID', 'M√£ CP', 'Ng√†y SK', 'T√≥m t·∫Øt', 'Scrape l√∫c', 'Ngu·ªìn'), show='headings', height=18)
for c in tree['columns']:
    tree.heading(c, text=c, anchor='w')
    tree.column(c, width=100)
tree.column('T√≥m t·∫Øt', width=450)
tree.tag_configure('new_scraped', background='#E8F5E9')
tree.tag_configure('nodate_row', background='#F5F5F5', foreground='#9E9E9E') # M√†u x√°m nh·∫°t
tree.tag_configure('co_tuc', background='#E1F5FE', foreground='#01579B')
tree.tag_configure('chuyen_nhuong', background='#FFF3E0', foreground='#E65100')
tree.tag_configure('niem_yet', background='#E8F5E9', foreground='#2E7D32')
tree.tag_configure('nghi_quyet', background='#F3E5F5', foreground='#7B1FA2')
# Th√™m d√≤ng n√†y v√†o khu v·ª±c c·∫•u h√¨nh tags c·ªßa Treeview
tree.tag_configure('priority_keyword', background='#FFF9C4', foreground='#D32F2F', font=('', 9, 'bold'))
tree.pack(fill='x', pady=5)

# 3. Khu v·ª±c ƒëi·ªÅu khi·ªÉn
ctrl_frame = ttk.LabelFrame(main_frame, text="‚öôÔ∏è H·ªá th·ªëng Scraper", padding="10")
ctrl_frame.pack(fill='x', pady=5)

ttk.Label(ctrl_frame, text="S·ªë lu·ªìng ch·∫°y song song:").pack(side='left', padx=5)
worker_combo = ttk.Combobox(ctrl_frame, values=["1", "2", "3", "4", "5", "7", "10"], state='readonly', width=5)
worker_combo.set("3")
worker_combo.pack(side='left', padx=5)

progress = ttk.Progressbar(ctrl_frame, length=250, mode='determinate')
progress.pack(side='left', padx=20)

run_btn = ttk.Button(ctrl_frame, text="üöÄ Ch·∫°y Scrapers", command=lambda: [run_btn.config(state=tk.DISABLED), threading.Thread(target=run_parallel_logic, args=(progress, run_btn), daemon=True).start()])
run_btn.pack(side='left', padx=5)
# --- TH√äM N√öT AUTO RUN V√ÄO ƒê√ÇY ---
auto_run_btn = ttk.Button(ctrl_frame, text="ü§ñ Auto Run", command=run_auto_script)
auto_run_btn.pack(side='left', padx=5)
# 4. Box n·ªôi dung chi ti·∫øt
ttk.Label(main_frame, text="N·ªôi dung chi ti·∫øt b·∫£n tin:", font=('', 9, 'bold')).pack(anchor='w', pady=(10, 0))
detail_box = tk.Text(main_frame, height=12, state=tk.DISABLED, wrap=tk.WORD, bg='#FCFCFC', padx=15, pady=15, font=('Segoe UI', 10))
detail_box.pack(fill='both', expand=True)

tree.bind('<<TreeviewSelect>>', on_item_select)

if __name__ == "__main__":
    update_display("today")
    
    # B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p t·ª± ƒë·ªông c·∫≠p nh·∫≠t sau m·ªói 5 ph√∫t
    root.after(300000, auto_refresh) 
    
    root.mainloop()