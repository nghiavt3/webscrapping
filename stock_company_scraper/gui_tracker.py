import sqlite3
import tkinter as tk
import sys
import hashlib
import time
import webbrowser
import re
from tkinter import ttk, messagebox
from datetime import datetime, date, timedelta
import os
import threading
import subprocess
import requests
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import winsound 

# --- TH∆Ø VI·ªÜN B·ªî SUNG ---
try:
    import google.generativeai as genai
except ImportError:
    pass

# --- 1. KI·ªÇM TRA QUY·ªÄN TRUY C·∫¨P ---
def check_access():
    if len(sys.argv) < 2:
        sys.exit("Truy c·∫≠p b·ªã ch·∫∑n! Vui l√≤ng kh·ªüi ƒë·ªông t·ª´ App Web.")

    received_token = sys.argv[1]
    valid_tokens = []
    for offset in [0, -1]:
        t_str = (datetime.now() + timedelta(minutes=offset)).strftime('%Y-%m-%d %H:%M')
        raw = f"MySecretKey_{t_str}"
        valid_tokens.append(hashlib.sha256(raw.encode()).hexdigest())

    if received_token not in valid_tokens:
        root_auth = tk.Tk()
        root_auth.withdraw()
        messagebox.showerror("L·ªói b·∫£o m·∫≠t", "Token h·∫øt h·∫°n ho·∫∑c kh√¥ng h·ª£p l·ªá!")
        root_auth.destroy()
        sys.exit()

check_access()

# --- 2. C·∫§U H√åNH D·ªÆ LI·ªÜU & AI ---
try:
    from spider_names import ALL_SPIDERS
    ALL_SPIDERS = sorted(ALL_SPIDERS) 
except ImportError:
    ALL_SPIDERS = [] 

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATABASE_NAME = os.path.join(BASE_DIR, 'stock_events.db')
current_view_data = [] 
last_count = 0 

# C·∫§U H√åNH AI CHU·∫®N (ƒê√£ s·ª≠a l·ªói 404)
try:
    genai.configure(api_key="AIzaSyBWGkET-D91usOftX82vdNcK9aBo69hNjc")
    AI_MODEL = genai.GenerativeModel('gemini-flash-latest')
    print("AI ƒë√£ s·∫µn s√†ng.")
except Exception as e:
    print(f"L·ªói kh·ªüi t·∫°o AI: {e}")

# --- 3. LOGIC X·ª¨ L√ù URL, AI & HI·ªÇN TH·ªä ---

def open_url(event):
    try:
        tags = event.widget.tag_names(tk.CURRENT)
        for tag in tags:
            if tag.startswith("http"):
                webbrowser.open(tag)
                return
    except Exception as e:
        print(f"L·ªói m·ªü link: {e}")

def highlight_urls(text_widget):
    content = text_widget.get("1.0", tk.END)
    url_pattern = r'(https?://[^\s\(\)\[\]\{\}\<\>]+)'
    for tag in text_widget.tag_names():
        if tag.startswith("http"): text_widget.tag_delete(tag)
    for match in re.finditer(url_pattern, content):
        start = f"1.0 + {match.start()} chars"
        end = f"1.0 + {match.end()} chars"
        url = match.group(0)
        text_widget.tag_add(url, start, end)
        text_widget.tag_config(url, foreground="#0066CC", underline=True)
        text_widget.tag_bind(url, "<Control-Button-1>", open_url)

def analyze_pdf_with_ai(pdf_url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(pdf_url, headers=headers, timeout=30, verify=False)
        if response.status_code != 200:
            return f"‚ùå L·ªói t·∫£i file: HTTP {response.status_code}"
        
        pdf_blob = response.content
        prompt = """
        H√£y ph√¢n t√≠ch file PDF ƒë√≠nh k√®m (c√≥ th·ªÉ l√† vƒÉn b·∫£n scan):
        1. T√≥m t·∫Øt 3 n·ªôi dung quan tr·ªçng nh·∫•t ·∫£nh h∆∞·ªüng ƒë·∫øn doanh nghi·ªáp.
        2. ƒê√°nh gi√° t√°c ƒë·ªông ƒë·∫øn gi√° c·ªï phi·∫øu: T√≠ch c·ª±c, Ti√™u c·ª±c hay Trung t√≠nh?
        3. Ch·∫•m ƒëi·ªÉm m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng: T·ª´ -10 (R·∫•t x·∫•u) ƒë·∫øn +10 (R·∫•t t·ªët).
        4. So s√°nh v·ªõi d·ªØ li·ªáu c√πng k·ª≥ v√† ƒë·ªãnh gi√° theo p/b ,p/e
        Y√™u c·∫ßu tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn v√† tr·ª±c di·ªán.
        """
        response_ai = AI_MODEL.generate_content([
            prompt,
            {"mime_type": "application/pdf", "data": pdf_blob}
        ])
        return response_ai.text
    except Exception as e:
        return f"‚ùå L·ªói AI: {str(e)}"
def clean_pdf_url(raw_url):
    """Tr√≠ch xu·∫•t link PDF th·ª±c t·ª´ link Google View ho·∫∑c AWS"""
    # N·∫øu link ch·ª©a tham s·ªë ?url= (ƒë·∫∑c tr∆∞ng c·ªßa Google GView)
    n = raw_url.find('url=')
    if n != -1:
        clean_url = raw_url[n+4:]
        # Gi·∫£i m√£ c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát n·∫øu c√≥ (v√≠ d·ª• %3A th√†nh :)
        from urllib.parse import unquote
        return unquote(clean_url)
    return raw_url
def trigger_ai_analysis():
    selected = tree.focus()
    if not selected:
        messagebox.showwarning("Ch√∫ √Ω", "Vui l√≤ng ch·ªçn m·ªôt tin tr√™n b·∫£ng!")
        return
    
    item_data = tree.item(selected)
    ticker = item_data['values'][1] # L·∫•y m√£ CP
    content = item_data['tags'][-1]
    pdf_match = re.search(r'https?://[^\s]+\.pdf', content)
    
    if not pdf_match:
        messagebox.showinfo("Th√¥ng tin", "Tin n√†y kh√¥ng ch·ª©a file PDF.")
        return

    raw_url = pdf_match.group(0)
    # S·ª¨ D·ª§NG H√ÄM L√ÄM S·∫†CH LINK ·ªû ƒê√ÇY
    pdf_url = clean_pdf_url(raw_url) 
    
    # Ki·ªÉm tra xem c√≥ ƒë√∫ng l√† PDF kh√¥ng
    if not pdf_url.lower().endswith('.pdf'):
        messagebox.showinfo("Th√¥ng tin", "Link n√†y kh√¥ng d·∫´n tr·ª±c ti·∫øp ƒë·∫øn file PDF.")
        return
    # Hi·ªÉn th·ªã th√¥ng b√°o ƒëang x·ª≠ l√Ω tr√™n giao di·ªán ch√≠nh
    detail_box.config(state=tk.NORMAL)
    detail_box.insert(tk.END, f"\n\nü§ñ ƒêANG PH√ÇN T√çCH AI CHO M√É {ticker}... Vui l√≤ng ƒë·ª£i c·ª≠a s·ªï m·ªõi.")
    detail_box.see(tk.END)
    detail_box.config(state=tk.DISABLED)
    
    def worker():
        result = analyze_pdf_with_ai(pdf_url)
        root.after(0, lambda: display_ai_popup(ticker, result, pdf_url))

    threading.Thread(target=worker, daemon=True).start()

def display_ai_popup(ticker, result, url):
    """T·∫°o m·ªôt c·ª≠a s·ªï Popup m·ªõi ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ AI"""
    popup = tk.Toplevel(root)
    popup.title(f"AI Analyst - M√£: {ticker}")
    popup.geometry("700x550")
    popup.configure(bg="#F0F2F5")

    # Header
    header = tk.Label(popup, text=f"B√ÅO C√ÅO PH√ÇN T√çCH AI - {ticker}", 
                      font=('Segoe UI', 14, 'bold'), bg="#F0F2F5", fg="#1A73E8")
    header.pack(pady=10)

    # Text Area
    text_frame = ttk.Frame(popup)
    text_frame.pack(fill='both', expand=True, padx=20, pady=5)
    
    ai_box = tk.Text(text_frame, wrap=tk.WORD, font=('Segoe UI', 11), 
                     padx=15, pady=15, bg="white", borderwidth=0)
    ai_box.pack(side='left', fill='both', expand=True)
    
    scrollbar = ttk.Scrollbar(text_frame, command=ai_box.yview)
    scrollbar.pack(side='right', fill='y')
    ai_box.config(yscrollcommand=scrollbar.set)

    # Ch√®n d·ªØ li·ªáu
    ai_box.insert(tk.END, f"Ngu·ªìn file: {url}\n")
    ai_box.insert(tk.END, "-"*50 + "\n\n")
    ai_box.insert(tk.END, result)
    
    highlight_urls(ai_box)
    ai_box.config(state=tk.DISABLED)

    # Footer
    btn_close = ttk.Button(popup, text="ƒê√≥ng", command=popup.destroy)
    btn_close.pack(pady=10)

# --- 4. TRUY V·∫§N D·ªÆ LI·ªÜU ---

def fetch_history_data(table_name):
    global current_view_data
    if not table_name: return
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute(f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table_name}")
        rows = cursor.fetchall()
        processed_data = []
        for row in rows:
            new_row = list(row)
            if not new_row[2] or new_row[2] == "None":
                new_row[2] = row[4].split(' ')[0] if row[4] else "N/A"
            processed_data.append(tuple(new_row))
        current_view_data = sorted(processed_data, key=lambda x: x[2], reverse=True)
        update_treeview(tree, current_view_data)
        root.title(f"Stock Scraper - {table_name} ({len(current_view_data)} b·∫£n ghi)")
    except Exception as e:
        messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ ƒë·ªçc b·∫£ng {table_name}: {e}")
    finally:
        conn.close()

def get_filtered_data(days_offset=None):
    today_dt = date.today()
    limit_date = today_dt - timedelta(days=days_offset-1) if days_offset else today_dt
    all_data = []
    if not os.path.exists(DATABASE_NAME): return []
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'event_%'")
        tables = [row[0] for row in cursor.fetchall()]
        for table in tables:
            query = f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table}"
            cursor.execute(query)
            for row in cursor.fetchall():
                raw_date_str = row[2] if row[2] and row[2] != "None" else row[4]
                if raw_date_str:
                    try:
                        clean_date_str = raw_date_str.split(' ')[0]
                        record_date = datetime.strptime(clean_date_str, '%Y-%m-%d').date()
                        if record_date >= limit_date:
                            new_row = list(row)
                            new_row[2] = clean_date_str
                            all_data.append(tuple(new_row))
                    except: continue
    finally: conn.close()
    return sorted(all_data, key=lambda x: x[2], reverse=True)

def get_newly_scraped_data():
    today_str = date.today().strftime('%Y-%m-%d')
    all_data = []
    if not os.path.exists(DATABASE_NAME): return []
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'event_%'")
        tables = [row[0] for row in cursor.fetchall()]
        for table in tables:
            query = f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table} WHERE scraped_at LIKE ?"
            cursor.execute(query, (f"{today_str}%",))
            for row in cursor.fetchall():
                new_row = list(row)
                if not new_row[2] or new_row[2] == "None":
                    new_row[2] = row[4].split(' ')[0]
                all_data.append(tuple(new_row))
    finally: conn.close()
    return sorted(all_data, key=lambda x: x[4], reverse=True)

def perform_search():
    query = search_var.get().strip().upper()
    if not query:
        # N·∫øu ƒë·ªÉ tr·ªëng √¥ t√¨m ki·∫øm, hi·ªÉn th·ªã l·∫°i to√†n b·ªô d·ªØ li·ªáu hi·ªán t·∫°i
        update_treeview(tree, current_view_data)
        return
    
    # L·ªçc d·ª±a tr√™n c·ªôt M√£ CP (index 1) ho·∫∑c n·ªôi dung T√≥m t·∫Øt (index 3)
    filtered = [
        row for row in current_view_data 
        if query in str(row[1]).upper() or query in str(row[3]).upper()
    ]
    
    update_treeview(tree, filtered)
    
    # C·∫≠p nh·∫≠t ti√™u ƒë·ªÅ ƒë·ªÉ bi·∫øt ƒëang xem k·∫øt qu·∫£ t√¨m ki·∫øm
    root.title(f"K·∫øt qu·∫£ t√¨m ki·∫øm cho: {query} ({len(filtered)} b·∫£n ghi)")

def run_parallel_logic(progress_bar, run_btn):
    total = len(ALL_SPIDERS)
    if total == 0: return
    try: max_parallel = int(worker_combo.get())
    except: max_parallel = 3
    completed = 0
    with ThreadPoolExecutor(max_workers=max_parallel) as executor:
        futures = {executor.submit(lambda s: subprocess.run(['scrapy', 'crawl', s], shell=True, cwd=BASE_DIR), s): s for s in ALL_SPIDERS}
        for future in as_completed(futures):
            completed += 1
            root.after(0, lambda p=(completed/total)*100: progress_bar.config(value=p))
            root.after(0, lambda c=completed, t=total: run_btn.config(text=f"‚è≥ ({c}/{t})..."))
    root.after(0, lambda: finalize_run(run_btn))

def finalize_run(run_btn):
    run_btn.config(state=tk.NORMAL, text="üöÄ Ch·∫°y Scrapers")
    messagebox.showinfo("Xong", "ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu m·ªõi!")
    update_display("today")

def auto_refresh():
    global last_count
    data_today = get_filtered_data(days_offset=1)
    current_count = len(data_today)
    if current_count > last_count and last_count != 0:
        winsound.Beep(1000, 500)
        update_display("today")
    last_count = current_count
    root.after(300000, auto_refresh)

# --- 5. GIAO DI·ªÜN CH√çNH ---

def update_treeview(tree_widget, data):
    today_str = date.today().strftime('%Y-%m-%d')
    for item in tree_widget.get_children(): tree_widget.delete(item)
    for row in data:
        summary_text = str(row[3]).lower()
        scraped_at = str(row[4])
        tags = []
        if scraped_at.startswith(today_str): tags.append('new_scraped')
        if "gi·∫£i th·ªÉ" in summary_text: tags.append('priority_keyword')
        elif "c·ªï t·ª©c" in summary_text: tags.append('co_tuc')
        
        tags.append(row[6]) 
        tree_widget.insert('', 'end', values=row[:6], tags=tags)

def update_display(mode="today"):
    global current_view_data, last_count
    if mode == "newly":
        current_view_data = get_newly_scraped_data()
        title_prefix = "M·ªõi c·∫≠p nh·∫≠t"
    else:
        days = 1 if mode == "today" else 7
        current_view_data = get_filtered_data(days_offset=days)
        title_prefix = 'H√¥m nay' if days==1 else '7 ng√†y qua'
    update_treeview(tree, current_view_data)
    root.title(f"Stock Scraper - {title_prefix} ({len(current_view_data)})")

def on_item_select(event):
    selected = tree.focus()
    if not selected: return
    tags = tree.item(selected, 'tags')
    if tags:
        detail_box.config(state=tk.NORMAL)
        detail_box.delete('1.0', tk.END)
        content = tags[-1] if tags[-1] else "Kh√¥ng c√≥ chi ti·∫øt."
        detail_box.insert(tk.END, content)
        highlight_urls(detail_box)
        detail_box.config(state=tk.DISABLED)

def on_combo_confirm(event=None):
    user_input = combo.get().strip().lower() # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng v√¨ t√™n table l√† ch·ªØ th∆∞·ªùng
    if not user_input: return
    
    # Danh s√°ch c√°c b·∫£ng th·ª±c t·∫ø (ƒë√£ c√≥ ti·ªÅn t·ªë event_)
    # 1. N·∫øu ng∆∞·ªùi d√πng g√µ th·∫≥ng 'event_yeg'
    if user_input in ALL_SPIDERS:
        fetch_history_data(user_input)
        return
        
    # 2. N·∫øu ng∆∞·ªùi d√πng ch·ªâ g√µ 'yeg', ta th·ª≠ t√¨m 'event_yeg'
    suggested_table = f"event_{user_input}"
    if suggested_table in ALL_SPIDERS:
        combo.set(suggested_table) # C·∫≠p nh·∫≠t l·∫°i t√™n ƒë·∫ßy ƒë·ªß v√†o combobox cho ƒë·∫πp
        fetch_history_data(suggested_table)
        return
    
    # 3. N·∫øu v·∫´n kh√¥ng th·∫•y, th√¥ng b√°o cho ng∆∞·ªùi d√πng
    messagebox.showwarning("Kh√¥ng t√¨m th·∫•y", f"Kh√¥ng t√¨m th·∫•y b·∫£ng d·ªØ li·ªáu n√†o li√™n quan ƒë·∫øn '{user_input}'")

def run_auto_script():
    script_path = os.path.join(BASE_DIR, 'auto_run.py')
    if os.path.exists(script_path):
        subprocess.Popen([sys.executable, script_path], cwd=BASE_DIR, shell=False)
        messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ k√≠ch ho·∫°t ch·∫ø ƒë·ªô Auto Run.")

# --- KH·ªûI T·∫†O GUI ---
root = tk.Tk()
root.title("Stock Scraper Pro")
root.geometry("1200x850")

main_frame = ttk.Frame(root, padding="15")
main_frame.pack(fill='both', expand=True)

# Top Bar
top_frame = ttk.LabelFrame(main_frame, text="üîç C√¥ng c·ª• l·ªçc nhanh", padding="10")
top_frame.pack(fill='x', pady=(0, 10))

ttk.Label(top_frame, text="M√£ CP:").pack(side='left', padx=2)
search_var = tk.StringVar()
search_entry = ttk.Entry(top_frame, textvariable=search_var, width=12)
search_entry.pack(side='left', padx=5)
search_entry.bind('<Return>', lambda e: perform_search())
ttk.Button(top_frame, text="T√¨m", command=perform_search).pack(side='left', padx=2)
ttk.Button(top_frame, text="üìÖ H√¥m nay", command=lambda: update_display("today")).pack(side='left', padx=2)
ttk.Button(top_frame, text="‚ö° M·ªõi c·∫≠p nh·∫≠t", command=lambda: update_display("newly")).pack(side='left', padx=2)

ttk.Label(top_frame, text=" | Ngu·ªìn:").pack(side='left', padx=5)
combo = ttk.Combobox(top_frame, values=ALL_SPIDERS, state='normal', width=22)
combo.pack(side='left', padx=2)
combo.bind('<<ComboboxSelected>>', on_combo_confirm)
combo.bind('<Return>', on_combo_confirm) # Th√™m d√≤ng n√†y ƒë·ªÉ nh·∫≠n l·ªánh khi nh·∫•n Enter
# Table
tree = ttk.Treeview(main_frame, columns=('ID', 'M√£ CP', 'Ng√†y SK', 'T√≥m t·∫Øt', 'Scrape l√∫c', 'Ngu·ªìn'), show='headings', height=15)
for c in tree['columns']:
    tree.heading(c, text=c, anchor='w')
    tree.column(c, width=100)
tree.column('T√≥m t·∫Øt', width=450)
tree.tag_configure('new_scraped', background='#E8F5E9')
tree.tag_configure('priority_keyword', background='#FFF9C4', font=('', 9, 'bold'))
tree.pack(fill='x', pady=5)

# Control Box
ctrl_frame = ttk.LabelFrame(main_frame, text="‚öôÔ∏è H·ªá th·ªëng Scraper", padding="10")
ctrl_frame.pack(fill='x', pady=5)

ttk.Label(ctrl_frame, text="S·ªë lu·ªìng:").pack(side='left', padx=5)
worker_combo = ttk.Combobox(ctrl_frame, values=["1", "3", "5", "10"], state='readonly', width=5)
worker_combo.set("3")
worker_combo.pack(side='left', padx=5)

progress = ttk.Progressbar(ctrl_frame, length=200, mode='determinate')
progress.pack(side='left', padx=15)

run_btn = ttk.Button(ctrl_frame, text="üöÄ Ch·∫°y Scrapers", command=lambda: [run_btn.config(state=tk.DISABLED), threading.Thread(target=run_parallel_logic, args=(progress, run_btn), daemon=True).start()])
run_btn.pack(side='left', padx=5)

ai_btn = ttk.Button(ctrl_frame, text="‚ú® Ph√¢n t√≠ch AI", command=trigger_ai_analysis)
ai_btn.pack(side='left', padx=5)

# Detail Box
ttk.Label(main_frame, text="N·ªôi dung chi ti·∫øt b·∫£n tin:", font=('', 9, 'bold')).pack(anchor='w', pady=(10, 0))
detail_box = tk.Text(main_frame, height=30, state=tk.DISABLED, wrap=tk.WORD, bg='#FFFFFF', padx=15, pady=15, font=('Segoe UI', 10))
detail_box.pack(fill='both', expand=True)

tree.bind('<<TreeviewSelect>>', on_item_select)

if __name__ == "__main__":
    update_display("today")
    root.after(300000, auto_refresh) 
    root.mainloop()