import sqlite3
import tkinter as tk
import sys
import hashlib
import time
import webbrowser
import re
from tkinter import ttk, messagebox
from datetime import datetime, date, timedelta
import os
import threading
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
import winsound 

# --- 1. KI·ªÇM TRA QUY·ªÄN TRUY C·∫¨P ---
def check_access():
    if len(sys.argv) < 2:
        sys.exit("Truy c·∫≠p b·ªã ch·∫∑n! Vui l√≤ng kh·ªüi ƒë·ªông t·ª´ App Web.")

    received_token = sys.argv[1]
    valid_tokens = []
    for offset in [0, -1]:
        t_str = (datetime.now() + timedelta(minutes=offset)).strftime('%Y-%m-%d %H:%M')
        raw = f"MySecretKey_{t_str}"
        valid_tokens.append(hashlib.sha256(raw.encode()).hexdigest())

    if received_token not in valid_tokens:
        root_auth = tk.Tk()
        root_auth.withdraw()
        messagebox.showerror("L·ªói b·∫£o m·∫≠t", "Token h·∫øt h·∫°n ho·∫∑c kh√¥ng h·ª£p l·ªá!")
        root_auth.destroy()
        sys.exit()

check_access()

# --- 2. C·∫§U H√åNH D·ªÆ LI·ªÜU ---
try:
    from spider_names import ALL_SPIDERS
    ALL_SPIDERS = sorted(ALL_SPIDERS) 
except ImportError:
    ALL_SPIDERS = [] 

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATABASE_NAME = os.path.join(BASE_DIR, 'stock_events.db')
current_view_data = [] 
last_count = 0 

# --- 3. LOGIC X·ª¨ L√ù URL & HI·ªÇN TH·ªä ---

def open_url(event):
    """M·ªü URL khi ng∆∞·ªùi d√πng nh·∫•n Ctrl + Click"""
    # L·∫•y danh s√°ch c√°c tag t·∫°i v·ªã tr√≠ con tr·ªè chu·ªôt hi·ªán t·∫°i
    try:
        tags = detail_box.tag_names(tk.CURRENT)
        for tag in tags:
            if tag.startswith("http"):
                webbrowser.open(tag)
                return
    except Exception as e:
        print(f"L·ªói m·ªü link: {e}")

def highlight_urls(text_widget):
    """Qu√©t vƒÉn b·∫£n v√† t·∫°o hyperlink cho c√°c URL"""
    content = text_widget.get("1.0", tk.END)
    # Regex nh·∫≠n di·ªán URL
    url_pattern = r'(https?://[^\s\(\)\[\]\{\}\<\>]+)'
    
    # X√≥a c√°c tag c≈©
    for tag in text_widget.tag_names():
        if tag.startswith("http"):
            text_widget.tag_delete(tag)

    for match in re.finditer(url_pattern, content):
        start = f"1.0 + {match.start()} chars"
        end = f"1.0 + {match.end()} chars"
        url = match.group(0)
        
        # T·∫°o tag mang t√™n ch√≠nh URL ƒë√≥
        text_widget.tag_add(url, start, end)
        text_widget.tag_config(url, foreground="#0066CC", underline=True)
        
        # B·∫Øt c√°c s·ª± ki·ªán cho tag n√†y
        text_widget.tag_bind(url, "<Control-Button-1>", open_url)
        text_widget.tag_bind(url, "<Enter>", lambda e: text_widget.config(cursor="hand2"))
        text_widget.tag_bind(url, "<Leave>", lambda e: text_widget.config(cursor=""))

# --- 4. TRUY V·∫§N D·ªÆ LI·ªÜU ---

def fetch_history_data(table_name):
    global current_view_data
    if not table_name: return
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute(f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table_name}")
        rows = cursor.fetchall()
        processed_data = []
        for row in rows:
            new_row = list(row)
            if not new_row[2] or new_row[2] == "None":
                new_row[2] = row[4].split(' ')[0] if row[4] else "N/A"
            processed_data.append(tuple(new_row))
        current_view_data = sorted(processed_data, key=lambda x: x[2], reverse=True)
        update_treeview(tree, current_view_data)
        root.title(f"Stock Scraper - {table_name} ({len(current_view_data)} b·∫£n ghi)")
    except Exception as e:
        messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ ƒë·ªçc b·∫£ng {table_name}: {e}")
    finally:
        conn.close()

def get_filtered_data(days_offset=None):
    today_dt = date.today()
    limit_date = today_dt - timedelta(days=days_offset-1) if days_offset else today_dt
    all_data = []
    if not os.path.exists(DATABASE_NAME): return []
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'event_%'")
        tables = [row[0] for row in cursor.fetchall()]
        for table in tables:
            query = f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table}"
            cursor.execute(query)
            for row in cursor.fetchall():
                raw_date_str = row[2] if row[2] and row[2] != "None" else row[4]
                if raw_date_str:
                    try:
                        clean_date_str = raw_date_str.split(' ')[0]
                        record_date = datetime.strptime(clean_date_str, '%Y-%m-%d').date()
                        if record_date >= limit_date:
                            new_row = list(row)
                            new_row[2] = clean_date_str
                            all_data.append(tuple(new_row))
                    except: continue
    finally: conn.close()
    return sorted(all_data, key=lambda x: x[2], reverse=True)

def get_newly_scraped_data():
    today_str = date.today().strftime('%Y-%m-%d')
    all_data = []
    if not os.path.exists(DATABASE_NAME): return []
    conn = sqlite3.connect(DATABASE_NAME)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'event_%'")
        tables = [row[0] for row in cursor.fetchall()]
        for table in tables:
            query = f"SELECT id, mcp, date, summary, scraped_at, web_source, details_clean FROM {table} WHERE scraped_at LIKE ?"
            cursor.execute(query, (f"{today_str}%",))
            for row in cursor.fetchall():
                new_row = list(row)
                if not new_row[2] or new_row[2] == "None":
                    new_row[2] = row[4].split(' ')[0]
                all_data.append(tuple(new_row))
    finally: conn.close()
    return sorted(all_data, key=lambda x: x[4], reverse=True)

def perform_search():
    query = search_var.get().strip().upper()
    if not query:
        update_treeview(tree, current_view_data)
        return
    filtered = [row for row in current_view_data if query in str(row[1]).upper()]
    update_treeview(tree, filtered)

def run_parallel_logic(progress_bar, run_btn):
    total = len(ALL_SPIDERS)
    if total == 0: return
    try: max_parallel = int(worker_combo.get())
    except: max_parallel = 3
    completed = 0
    with ThreadPoolExecutor(max_workers=max_parallel) as executor:
        futures = {executor.submit(lambda s: subprocess.run(['scrapy', 'crawl', s], shell=True, cwd=BASE_DIR), s): s for s in ALL_SPIDERS}
        for future in as_completed(futures):
            completed += 1
            root.after(0, lambda p=(completed/total)*100: progress_bar.config(value=p))
            root.after(0, lambda c=completed, t=total: run_btn.config(text=f"‚è≥ ({c}/{t})..."))
    root.after(0, lambda: finalize_run(run_btn))

def finalize_run(run_btn):
    run_btn.config(state=tk.NORMAL, text="üöÄ Ch·∫°y Scrapers")
    messagebox.showinfo("Xong", "ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu m·ªõi!")
    update_display("today")

def auto_refresh():
    global last_count
    data_today = get_filtered_data(days_offset=1)
    current_count = len(data_today)
    if current_count > last_count and last_count != 0:
        winsound.Beep(1000, 500)
        update_display("today")
    last_count = current_count
    root.after(300000, auto_refresh)

# --- 5. GIAO DI·ªÜN CH√çNH ---

def update_treeview(tree_widget, data):
    today_str = date.today().strftime('%Y-%m-%d')
    for item in tree_widget.get_children(): tree_widget.delete(item)
    for row in data:
        row_id = str(row[0]) if row[0] else ""
        summary_text = str(row[3]).lower()
        scraped_at = str(row[4])
        tags = []
        if scraped_at.startswith(today_str): tags.append('new_scraped')
        if "NODATE" in row_id: tags.append('nodate_row')
        else:
            if "gi·∫£i th·ªÉ" in summary_text or "thu h·ªìi v·ªën" in summary_text: tags.append('priority_keyword')
            elif "c·ªï t·ª©c" in summary_text: tags.append('co_tuc')
            elif "chuy·ªÉn nh∆∞·ª£ng" in summary_text: tags.append('chuyen_nhuong')
            elif "ni√™m y·∫øt c·ªï phi·∫øu" in summary_text: tags.append('niem_yet')
            elif "ngh·ªã quy·∫øt ƒëhƒëcƒë" in summary_text: tags.append('nghi_quyet')
        
        # Tag cu·ªëi c√πng lu√¥n ch·ª©a n·ªôi dung Details ƒë·ªÉ h√†m on_item_select l·∫•y ra
        tags.append(row[6]) 
        tree_widget.insert('', 'end', values=row[:6], tags=tags)

def update_display(mode="today"):
    global current_view_data, last_count
    if mode == "newly":
        current_view_data = get_newly_scraped_data()
        title_prefix = "M·ªõi c·∫≠p nh·∫≠t"
    else:
        days = 1 if mode == "today" else 7
        current_view_data = get_filtered_data(days_offset=days)
        title_prefix = 'H√¥m nay' if days==1 else '7 ng√†y qua'
    if mode in ["newly", "today"]: last_count = len(current_view_data)
    update_treeview(tree, current_view_data)
    search_var.set("")
    root.title(f"Stock Scraper - {title_prefix} ({len(current_view_data)})")

def on_item_select(event):
    selected = tree.focus()
    if not selected: return
    tags = tree.item(selected, 'tags')
    if tags:
        detail_box.config(state=tk.NORMAL)
        detail_box.delete('1.0', tk.END)
        
        # N·ªôi dung n·∫±m ·ªü tag cu·ªëi c√πng
        content = tags[-1] if tags[-1] else "Kh√¥ng c√≥ chi ti·∫øt."
        detail_box.insert(tk.END, content)
        
        # Qu√©t v√† t·∫°o Link
        highlight_urls(detail_box)
        
        # Th√™m ghi ch√∫ h∆∞·ªõng d·∫´n n·∫øu c√≥ link
        if "http" in content:
            detail_box.insert(tk.END, "\n\n" + "-"*30)
            detail_box.insert(tk.END, "\nüí° M·∫πo: Gi·ªØ Ctrl + Click v√†o ƒë∆∞·ªùng d·∫´n m√†u xanh ƒë·ªÉ m·ªü tr√¨nh duy·ªát.")
            
        detail_box.config(state=tk.DISABLED)

def on_combo_confirm(event=None):
    user_input = combo.get().strip().lower()
    if not user_input: return
    if user_input in ALL_SPIDERS:
        fetch_history_data(user_input)
    else:
        matches = [s for s in ALL_SPIDERS if user_input in s]
        if matches:
            combo.set(matches[0])
            fetch_history_data(matches[0])
        else:
            messagebox.showwarning("Kh√¥ng t√¨m th·∫•y", f"Kh√¥ng t√¨m th·∫•y ngu·ªìn '{user_input}'")

def run_auto_script():
    script_path = os.path.join(BASE_DIR, 'auto_run.py')
    if os.path.exists(script_path):
        subprocess.Popen([sys.executable, script_path], cwd=BASE_DIR, shell=False)
        messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ k√≠ch ho·∫°t ch·∫ø ƒë·ªô Auto Run.")
    else:
        messagebox.showwarning("L·ªói", "Kh√¥ng t√¨m th·∫•y file auto_run.py")

# --- KH·ªûI T·∫†O GUI ---
root = tk.Tk()
root.title("Stock Scraper Pro")
root.geometry("1200x850")

main_frame = ttk.Frame(root, padding="15")
main_frame.pack(fill='both', expand=True)

# 1. Top Bar
top_frame = ttk.LabelFrame(main_frame, text="üîç C√¥ng c·ª• l·ªçc nhanh", padding="10")
top_frame.pack(fill='x', pady=(0, 10))

ttk.Label(top_frame, text="M√£ CP:").pack(side='left', padx=2)
search_var = tk.StringVar()
search_entry = ttk.Entry(top_frame, textvariable=search_var, width=12)
search_entry.pack(side='left', padx=5)
search_entry.bind('<Return>', lambda e: perform_search())
ttk.Button(top_frame, text="T√¨m", command=perform_search).pack(side='left', padx=2)

ttk.Separator(top_frame, orient='vertical').pack(side='left', fill='y', padx=10)
ttk.Button(top_frame, text="üìÖ H√¥m nay", command=lambda: update_display("today")).pack(side='left', padx=2)
ttk.Button(top_frame, text="‚ö° M·ªõi c·∫≠p nh·∫≠t", command=lambda: update_display("newly")).pack(side='left', padx=2)
ttk.Button(top_frame, text="üóìÔ∏è 7 Ng√†y qua", command=lambda: update_display("week")).pack(side='left', padx=2)

ttk.Label(top_frame, text=" | Ngu·ªìn:").pack(side='left', padx=5)
combo = ttk.Combobox(top_frame, values=ALL_SPIDERS, state='normal', width=22)
combo.pack(side='left', padx=2)
combo.bind('<<ComboboxSelected>>', on_combo_confirm)
combo.bind('<Return>', on_combo_confirm)

# 2. Table
tree = ttk.Treeview(main_frame, columns=('ID', 'M√£ CP', 'Ng√†y SK', 'T√≥m t·∫Øt', 'Scrape l√∫c', 'Ngu·ªìn'), show='headings', height=18)
for c in tree['columns']:
    tree.heading(c, text=c, anchor='w')
    tree.column(c, width=100)
tree.column('T√≥m t·∫Øt', width=450)
tree.tag_configure('new_scraped', background='#E8F5E9')
tree.tag_configure('nodate_row', background='#F5F5F5', foreground='#9E9E9E')
tree.tag_configure('co_tuc', background='#E1F5FE', foreground='#01579B')
tree.tag_configure('chuyen_nhuong', background='#FFF3E0', foreground='#E65100')
tree.tag_configure('priority_keyword', background='#FFF9C4', foreground='#D32F2F', font=('', 9, 'bold'))
tree.pack(fill='x', pady=5)

# 3. Control Box
ctrl_frame = ttk.LabelFrame(main_frame, text="‚öôÔ∏è H·ªá th·ªëng Scraper", padding="10")
ctrl_frame.pack(fill='x', pady=5)

ttk.Label(ctrl_frame, text="S·ªë lu·ªìng:").pack(side='left', padx=5)
worker_combo = ttk.Combobox(ctrl_frame, values=["1", "3", "5", "10"], state='readonly', width=5)
worker_combo.set("3")
worker_combo.pack(side='left', padx=5)

progress = ttk.Progressbar(ctrl_frame, length=250, mode='determinate')
progress.pack(side='left', padx=20)

run_btn = ttk.Button(ctrl_frame, text="üöÄ Ch·∫°y Scrapers", command=lambda: [run_btn.config(state=tk.DISABLED), threading.Thread(target=run_parallel_logic, args=(progress, run_btn), daemon=True).start()])
run_btn.pack(side='left', padx=5)

auto_run_btn = ttk.Button(ctrl_frame, text="ü§ñ Auto Run", command=run_auto_script)
auto_run_btn.pack(side='left', padx=5)

# 4. Detail Box (N∆°i hi·ªÉn th·ªã n·ªôi dung v√† Link)
ttk.Label(main_frame, text="N·ªôi dung chi ti·∫øt b·∫£n tin:", font=('', 9, 'bold')).pack(anchor='w', pady=(10, 0))
detail_box = tk.Text(main_frame, height=12, state=tk.DISABLED, wrap=tk.WORD, 
                     bg='#FFFFFF', padx=15, pady=15, font=('Segoe UI', 10),
                     undo=True)
detail_box.pack(fill='both', expand=True)

tree.bind('<<TreeviewSelect>>', on_item_select)

if __name__ == "__main__":
    update_display("today")
    root.after(300000, auto_refresh) 
    root.mainloop()