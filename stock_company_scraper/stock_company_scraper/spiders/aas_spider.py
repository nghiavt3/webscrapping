import scrapy
from stock_company_scraper.items import EventItem
from datetime import datetime
import re

# Gi·ªØ nguy√™n h√†m chuy·ªÉn ƒë·ªïi ng√†y th√°ng v√¨ n√≥ h·ª£p l·ªá
def convert_date_to_iso8601(vietnam_date_str):
    """
    Chuy·ªÉn ƒë·ªïi chu·ªói ng√†y th√°ng t·ª´ ƒë·ªãnh d·∫°ng 'DD/MM/YYYY' sang 'YYYY-MM-DD' (ISO 8601).
    """
    if not vietnam_date_str:
        return None
    input_format = '%d/%m/%Y'
    output_format = '%Y-%m-%d'

    try:
        # X·ª≠ l√Ω chu·ªói date c√≥ th·ªÉ l√† tuple ho·∫∑c ch·ª©a d·∫•u ph·∫©y/kho·∫£ng tr·∫Øng
        cleaned_date_str = str(vietnam_date_str).replace(',', '').replace('(', '').replace(')', '').strip()
        
        date_object = datetime.strptime(cleaned_date_str, input_format)
        iso_date_str = date_object.strftime(output_format)
        
        return iso_date_str
    
    except ValueError as e:
        print(f"‚ö†Ô∏è L·ªói chuy·ªÉn ƒë·ªïi ng√†y th√°ng '{vietnam_date_str}' (ph·∫£i l√† DD/MM/YYYY): {e}")
        return None

class EventSpider(scrapy.Spider):
    name = 'event_aas'
    allowed_domains = ['aas.com.vn'] 
    start_urls = ['https://aas.com.vn/danh-muc-thong-tin-co-dong/cong-bo-thong-tin/'] 

    def parse(self, response):
        # S·ª¨A L·ªñI M·ªöI: S·ª≠ d·ª•ng XPath d·ª±a tr√™n v·ªã tr√≠ c·ªßa container ch√≠nh
        # T√¨m th·∫ª div ch·ª©a c·∫£ featured article v√† list articles
        # D√πng contains(@class, "grid") v√† contains(@class, "gap-6") nh∆∞ng ki·ªÉm tra l·∫°i t√≠nh ch√≠nh x√°c
        
        # Th·ª≠ XPath d·ª±a tr√™n div ch·ª©a t·∫•t c·∫£ c√°c b√†i vi·∫øt:
        # N·∫øu trang web d√πng Playwright, selector n√†y ph·∫£i ho·∫°t ƒë·ªông khi n·ªôi dung ƒë∆∞·ª£c t·∫£i.
        container = response.xpath('//div[contains(@class, "grid grid-cols-1 xl:grid-cols-2")]')
        
        if not container:
            # Th·ª≠ ph∆∞∆°ng ph√°p d√≤ t√¨m n·∫øu selector tr√™n v·∫´n kh√¥ng ho·∫°t ƒë·ªông
            # Th·ª≠ t√¨m th·∫ª cha c·ªßa m·ªôt ph·∫ßn t·ª≠ ·ªïn ƒë·ªãnh, v√≠ d·ª•: t√¨m th·∫ª cha c·ªßa ti√™u ƒë·ªÅ "C√îNG B·ªê TH√îNG TIN"
            container = response.xpath('//h1[text()="C√îNG B·ªê TH√îNG TIN"]/following-sibling::div[1]')
            if not container:
                 self.logger.error("üö´ L·ªñI: Kh√¥ng t√¨m th·∫•y container b√†i vi·∫øt ch√≠nh. Ki·ªÉm tra l·∫°i XPath.")
                 return

        # L·∫•y container ch√≠nh (ch·∫Øc ch·∫Øn ch·ªâ l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n n·∫øu c√≥ nhi·ªÅu k·∫øt qu·∫£)
        container = container.get()

        # =========================================================
        # 1. Tr√≠ch xu·∫•t B√†i vi·∫øt N·ªïi b·∫≠t (Featured Article - C·ªôt 1)
        # S·ª≠ d·ª•ng CSS Selector ƒë∆°n gi·∫£n: .cbtt-cus.first-item
        featured_item = container.css('.cbtt-cus.first-item')
        if featured_item:
            yield self.extract_item(featured_item, is_featured=True)

        # =========================================================
        # 2. Tr√≠ch xu·∫•t Danh s√°ch B√†i vi·∫øt kh√°c (List Articles - C·ªôt 2)
        # Ch·ªçn div th·ª© 2 (c·ªôt danh s√°ch) trong container ch√≠nh
        list_container = container.xpath('./div[2]')
        
        # Ch·ªçn c√°c m·ª•c b√†i vi·∫øt con tr·ª±c ti·∫øp trong list_container
        list_items = list_container.xpath('./div[contains(@class, "flex flex-col sm:flex-row")]')
        
        for item in list_items:
            yield self.extract_item(item, is_featured=False)
            
    def extract_item(self, selector, is_featured=False):
        
        e_item = EventItem()
        e_item['mcp'] = 'AAS'
        e_item['web_source'] = self.allowed_domains[0]
        
        # === Ng√†y ƒëƒÉng ===
        # L·∫•y ng√†y (c√πng selector cho c·∫£ featured v√† list)
        date_raw = selector.css('div.flex.items-center.gap-2 p::text').get() 
        e_item['date'] = convert_date_to_iso8601(date_raw)
        
        # === Ti√™u ƒë·ªÅ & T√≥m t·∫Øt & Link ===
        if is_featured:
            # B√†i vi·∫øt n·ªïi b·∫≠t (Featured)
            title_raw = selector.css('h2.truncate-1row::text').get()
            summary_raw = selector.css('p.truncate-2row::text').get()
            url_raw = selector.css('a.link-yellow::attr(href)').get()
        else:
            # B√†i vi·∫øt danh s√°ch (List)
            # D√πng CSS Selector cho Title v√† T√≥m t·∫Øt v√¨ n√≥ ng·∫Øn v√† d·ªÖ ƒë·ªçc h∆°n khi ƒë√£ kh·∫Øc ph·ª•c l·ªói c√∫ ph√°p
            title_raw = selector.css('a.text-body-md-semibold::text').get()
            summary_raw = selector.css('div.text-body-md-regular.text-text-content::text').get()
            url_raw = selector.css('a.link-yellow::attr(href)').get()
        
        # L√†m s·∫°ch d·ªØ li·ªáu v√† g√°n v√†o item
        e_item['summary'] = title_raw.strip() if title_raw else None
        summary_cleaned = summary_raw.strip() if summary_raw else None
        e_item['details_raw'] = (e_item['summary'] or '') + '\n' + (summary_cleaned or '') + '\n' + (url_raw or '')
        
        return e_item