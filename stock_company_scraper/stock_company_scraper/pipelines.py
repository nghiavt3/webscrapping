# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html


# useful for handling different item types with a single interface
from itemadapter import ItemAdapter
from firebase_admin import credentials, initialize_app,get_app, App, firestore
import logging
import os


class StockCompanyScraperPipeline:
    def process_item(self, item, spider):
        if item.get('details_raw'):
            details = item['details_raw']

            # 1. Thay th·∫ø m√£ h√≥a HTML th√†nh k√Ω t·ª± d·ªÖ ƒë·ªçc
            details_clean = details.replace('&lt;br&gt;', '\n')
            details_clean = details_clean.replace('&amp;nbsp;', ' ')
            details_clean = details_clean.replace('<br>', '\n')
            details_clean = details_clean.replace('&nbsp;',' ')
            details_clean = details_clean.replace('v\xa0 \xa0 \xa0 \xa0 \xa0', ' ') # X·ª≠ l√Ω c√°c kho·∫£ng tr·∫Øng unicode
            
            
            # Th√™m tr∆∞·ªùng s·∫°ch v√†o Item (ho·∫∑c thay th·∫ø tr∆∞·ªùng raw)
            item['details_clean'] = details_clean
            
            # X√≥a tr∆∞·ªùng th√¥ (t√πy ch·ªçn)
            del item['details_raw']
        return item


# stock_company_scraper/pipelines.py

class FirebaseStoragePipeline:
    
    def __init__(self):
        # 1. Kh·ªüi t·∫°o Firebase
        # ƒê∆∞·ªùng d·∫´n t·ªõi file key ƒë√£ t·∫£i xu·ªëng
        key_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'firebase-admin-key.json')
        print("duong dan ne :" + key_path)
        logging.info("K·∫øt n·ªëi " + key_path)
        try:
            cred = credentials.Certificate(key_path)
            # Thay th·∫ø b·∫±ng t√™n d·ª± √°n Firebase c·ªßa b·∫°n n·∫øu c·∫ßn
            #if not len(list(App._get_service())):
            initialize_app(cred, {'projectId': 'yourwebscrapping-d300c'}) 
            self.db = firestore.client()
            logging.info("K·∫øt n·ªëi Firebase Firestore th√†nh c√¥ng.")
        except Exception as e:
            logging.error(f"L·ªói k·∫øt n·ªëi Firebase: {e}")
            self.db = None
            
        # T√™n collection trong Firestore ƒë·ªÉ l∆∞u d·ªØ li·ªáu
        self.collection_name = 'stock_events'

    def process_item(self, item, spider):
        if not self.db:
            logging.warning("B·ªè qua Item v√¨ kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Firebase.")
            return item

        # Chuy·ªÉn Item Scrapy sang dictionary
        data = dict(item)
        
        # T·∫°o ID duy nh·∫•t cho s·ª± ki·ªán ƒë·ªÉ so s√°nh. 
        # K·∫øt h·ª£p T√≥m t·∫Øt v√† Ng√†y l√† m·ªôt c√°ch hi·ªáu qu·∫£ ƒë·ªÉ x√°c ƒë·ªãnh t√≠nh duy nh·∫•t
        event_id = f"{data.get('summary')}_{data.get('date')}"
        
        # 2. L√ÄM S·∫†CH ID: Thay th·∫ø k√Ω t·ª± '/' b·∫±ng '-' ho·∫∑c x√≥a n√≥.
         # T√™n Document ID kh√¥ng ƒë∆∞·ª£c ch·ª©a k√Ω t·ª± '/'
        event_id_clean = event_id.replace('/', '-') 
        event_id_clean = event_id_clean.replace('.', '_') # Thay th·∫ø d·∫•u ch·∫•m b·∫±ng g·∫°ch d∆∞·ªõi

        # 3. Lo·∫°i b·ªè c√°c kho·∫£ng tr·∫Øng th·ª´a ·ªü ƒë·∫ßu/cu·ªëi
        event_id_clean = event_id_clean.strip()

        # 4. Tr√°nh ID qu√° d√†i: Gi·ªõi h·∫°n ƒë·ªô d√†i ID (t√πy ch·ªçn)
        if len(event_id_clean) > 150:
            event_id_clean = event_id_clean[:150]



        # 2. So s√°nh D·ªØ li·ªáu C≈© v√† M·ªõi (Ki·ªÉm tra xem t√†i li·ªáu ƒë√£ t·ªìn t·∫°i ch∆∞a)
        doc_ref = self.db.collection(self.collection_name).document(event_id_clean)
        
        if doc_ref.get().exists:
            # D·ªØ li·ªáu ƒë√£ c√≥ trong Database
            logging.info(f"S·ª± ki·ªán ƒë√£ t·ªìn t·∫°i, kh√¥ng c·∫ßn th√¥ng b√°o: {event_id_clean}")
        else:
            # D·ªØ li·ªáu M·ªöI!
            logging.info(f"S·ª∞ KI·ªÜN M·ªöI ƒê∆Ø·ª¢C PH√ÅT HI·ªÜN: {event_id_clean}")
            
            # 3. L∆∞u d·ªØ li·ªáu m·ªõi v√†o Firestore
            doc_ref.set(data)
            logging.info(f"ƒê√£ l∆∞u d·ªØ li·ªáu m·ªõi v√†o Firebase: {event_id_clean}")
            
            # 4. Ph√°t th√¥ng b√°o (Ch·ª©c nƒÉng Th√¥ng b√°o)
            self._send_notification(data)
            
        return item

    def _send_notification(self, data):
        """
        Th·ª±c hi·ªán logic g·ª≠i th√¥ng b√°o (Telegram, Email, Desktop, v.v.)
        """


        try:
            summary = data.get('summary', 'S·ª± ki·ªán m·ªõi')
            date = data.get('date', 'N/A')
            # **********************************************
            # V√ç D·ª§ CH·ª®C NƒÇNG TH√îNG B√ÅO TH·ª∞C T·∫æ
            # **********************************************
            
            # V√≠ d·ª• ƒë∆°n gi·∫£n: In ra console ƒë·ªÉ ki·ªÉm tra
            print("\n==============================================")
            print(f"üö® TH√îNG B√ÅO: S·ª∞ KI·ªÜN C√îNG TY M·ªöI! üö®")
            print(f"Ng√†y: {date}")
            print(f"T√≥m t·∫Øt: {summary}")
            print("==============================================")
            
            # **********************************************
            # N·∫øu d√πng Email/Telegram, b·∫°n s·∫Ω ƒë·∫∑t m√£ g·ªçi API ·ªü ƒë√¢y
            # V√≠ d·ª•: send_telegram_message(f"Tin m·ªõi CAT: {summary}")
            # **********************************************
            
        except Exception as e:
            logging.error(f"L·ªói khi g·ª≠i th√¥ng b√°o: {e}")


import sqlite3
from plyer import notification # Th√™m import plyer
#import logging
import json # Import th∆∞ vi·ªán json
# L·∫•y t√™n database v√† b·∫£ng t·ª´ settings (ho·∫∑c ƒë·∫∑t m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥)
DATABASE_NAME = 'stock_events.db'
#TABLE_NAME = 'events_history'
class SQLiteStoragePipeline:
    
    def open_spider(self, spider):
        """K·∫øt n·ªëi database v√† t·∫°o b·∫£ng n·∫øu ch∆∞a t·ªìn t·∫°i."""
        # L·∫•y c·∫•u h√¨nh t·ª´ settings.py
        self.db_name = spider.settings.get('SQLITE_DATABASE_NAME', DATABASE_NAME)
       # self.table_name = spider.settings.get('SQLITE_TABLE_NAME', TABLE_NAME)
        self.table_name = spider.name
        # K·∫øt n·ªëi
        self.conn = sqlite3.connect(self.db_name)
        self.cursor = self.conn.cursor()
        
        # T·∫°o b·∫£ng (N·∫øu 'summary' v√† 'date' l√† tr∆∞·ªùng d·ªØ li·ªáu ch√≠nh ƒë·ªÉ so s√°nh)
        self.cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.table_name} (
                id INTEGER PRIMARY KEY,
                unique_key TEXT UNIQUE,  -- Tr∆∞·ªùng d√πng ƒë·ªÉ so s√°nh (ƒë·∫£m b·∫£o t√≠nh duy nh·∫•t)
                mcp TEXT,
                summary TEXT,
                date TEXT,
                web_source TEXT,
                details_clean TEXT,
                scraped_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        self.conn.commit()
        logging.info(f"ƒê√£ m·ªü k·∫øt n·ªëi SQLite v√† t·∫°o b·∫£ng '{self.table_name}'.")
        # L·∫•y t√™n file log t·ª´ settings
        self.log_file = spider.settings.get('NEW_EVENTS_LOG_FILE', 'new_events_today.txt')
        
        # D·ªçn d·∫πp file log c≈© (ƒë·ªÉ m·ªói l·∫ßn ch·∫°y l√† d·ªØ li·ªáu m·ªõi trong ng√†y)
        if os.path.exists(self.log_file):
            os.remove(self.log_file)

    def close_spider(self, spider):
        """ƒê√≥ng k·∫øt n·ªëi database khi Spider k·∫øt th√∫c."""
        self.conn.close()
        logging.info("ƒê√£ ƒë√≥ng k·∫øt n·ªëi SQLite.")
        
    def process_item(self, item, spider):
        """X·ª≠ l√Ω, so s√°nh v√† l∆∞u tr·ªØ Item."""
        data = dict(item)
        
        # 1. T·∫°o Kh√≥a Duy nh·∫•t (UNIQUE KEY)
        # S·ª≠ d·ª•ng T√≥m t·∫Øt v√† Ng√†y ƒë·ªÉ t·∫°o kh√≥a so s√°nh
        unique_key = f"{data.get('summary', '')}_{data.get('date', '')}".replace('/', '-').strip()
        
        # 2. So s√°nh: Ki·ªÉm tra xem unique_key ƒë√£ t·ªìn t·∫°i ch∆∞a
        self.cursor.execute(f"SELECT id FROM {self.table_name} WHERE unique_key = ?", (unique_key,))
        
        if self.cursor.fetchone():
            # D·ªØ li·ªáu ƒê√É T·ªíN T·∫†I
            spider.logger.info(f"S·ª± ki·ªán ƒë√£ t·ªìn t·∫°i, b·ªè qua: {unique_key[:50]}...")
            return item
        else:
            # D·ªØ li·ªáu M·ªöI!
            spider.logger.info(f"üö® S·ª∞ KI·ªÜN M·ªöI ƒê∆Ø·ª¢C PH√ÅT HI·ªÜN: {unique_key[:50]}...")
            
            # 3. L∆∞u d·ªØ li·ªáu m·ªõi v√†o SQLite
            try:
                self.cursor.execute(f"""
                    INSERT INTO {self.table_name} (unique_key,mcp, summary, date,web_source, details_clean)
                    VALUES (?, ?, ?, ?, ?,?)
                """, (
                    unique_key,
                    data.get('mcp'),
                    data.get('summary'),
                    data.get('date'),
                    data.get('web_source'),
                    data.get('details_clean', ''), # Gi·∫£ ƒë·ªãnh b·∫°n c√≥ tr∆∞·ªùng full_content
                    
                ))
                self.conn.commit()
                # Ghi d·ªØ li·ªáu m·ªõi v√†o file log
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(data, ensure_ascii=False) + '\n')
                # 4. Ph√°t th√¥ng b√°o
                if not os.path.exists('__notified_today'):
                    self._send_notification(data)
                    # T·∫°o c·ªù ƒë·ªÉ tr√°nh th√¥ng b√°o li√™n t·ª•c n·∫øu c√≥ nhi·ªÅu tin m·ªõi
                    open('__notified_today', 'w').close()
                
            except sqlite3.Error as e:
                spider.logger.error(f"L·ªói khi INSERT v√†o SQLite: {e}")

            return item

    def _send_notification(self, data):

        # L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa file log
        log_file_path = os.path.abspath(self.log_file)
        """Th·ª±c hi·ªán ch·ª©c nƒÉng g·ª≠i th√¥ng b√°o (in ra console ƒë·ªÉ v√≠ d·ª•)."""
        summary = data.get('summary', 'S·ª± ki·ªán m·ªõi kh√¥ng r√µ r√†ng')
        date = data.get('date', 'N/A')
        # Ti√™u ƒë·ªÅ th√¥ng b√°o
        title = "üì¢ S·ª∞ KI·ªÜN C·ªî PHI·∫æU M·ªöI"
        
        # N·ªôi dung th√¥ng b√°o
        message = f"M√£: CAT | Ng√†y: {date}\n{summary}"
        try:

            # V√¨ plyer kh√¥ng h·ªó tr·ª£ click, ch√∫ng ta s·∫Ω in l·ªánh ra m√†n h√¨nh ƒë·ªÉ
            # ng∆∞·ªùi d√πng t·ª± ch·∫°y ho·∫∑c t√≠ch h·ª£p v√†o h·ªá th·ªëng l·∫≠p l·ªãch (Cron/Task Scheduler)
        
            if os.name == 'nt': # Windows
                open_command = f'start "" "{log_file_path}"'
            elif os.name == 'posix': # Linux/macOS
                open_command = f'open "{log_file_path}"' # Ho·∫∑c 'xdg-open' tr√™n Linux
            else:
                open_command = f"Vui l√≤ng m·ªü file: {log_file_path}"
            # G·ª≠i th√¥ng b√°o Desktop
            notification.notify(
                title=title,
                message=message,
                # T√™n ·ª©ng d·ª•ng hi·ªÉn th·ªã trong th√¥ng b√°o
                app_name='Scrapy Stock Tracker', 
                # Icon s·∫Ω hi·ªÉn th·ªã (ch·ªâ ho·∫°t ƒë·ªông v·ªõi file .ico tr√™n Windows)
                # app_icon='path/to/icon.ico', 
                timeout=10 # Th·ªùi gian hi·ªÉn th·ªã (gi√¢y)
            )
           # self.spider.logger.info(f"L·ªÜNH M·ªû FILE LOG: {open_command}")
            
        except Exception as e:
            # Th√¥ng b√°o n·∫øu plyer kh√¥ng th·ªÉ g·ª≠i (v√≠ d·ª•: thi·∫øu dependency c·ªßa OS)
            self.spider.logger.error(f"‚ùå L·ªói g·ª≠i th√¥ng b√°o Desktop (Plyer): {e}")
        print("\n==============================================")
        print("üîî TH√îNG B√ÅO: S·ª∞ KI·ªÜN C·ªî PHI·∫æU M·ªöI! üîî")
        print(f"Ng√†y: {date}")
        print(f"T√≥m t·∫Øt: {summary}")
        print("==============================================")
        
        # NOTE: B·∫°n c√≥ th·ªÉ t√≠ch h·ª£p API Telegram, Zalo, Email ·ªü ƒë√¢y.